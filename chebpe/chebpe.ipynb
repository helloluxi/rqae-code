{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e8b22b",
   "metadata": {},
   "source": [
    "## ChebPE\n",
    "\n",
    "Originally release at https://github.com/qiskit-community/ChebAE/blob/main/chebpe.ipynb\n",
    "\n",
    "This jupyter notebook presents a modified version of the ChebAE algorithm from [arXiv:2207.08628](https://arxiv.org/abs/2207.08628). Say $a \\in [0,1]$ is an amplitude. Given an oracle that for a parameter $k$ tosses a coin that comes up heads with probability\n",
    "$$\\sin^2( (2k+1) \\arcsin(a) )  $$\n",
    "at cost $k$, the objective is to estimate the probability $a^2$ with minimal cost. The ChebAE algorithm estimates the amplitude $a$. The ChebPE algorithm presented in this notebook modifies ChebAE to estimate the probability $p := a^2$ instead.\n",
    "\n",
    "It was observed that $\\sin^2( (2k+1) \\arcsin(a) ) = T^2_n(a)$ where $n = 2k+1$, where $T_n$ is the $n$'th Chebyshev polynomial of the first kind. In this modified version we are hence interested in $T^2_n(\\sqrt{p})$. Fortunately, this function behaves rather similarly to $T^2_n(a)$: the function oscillates as a function of $p$, and the slope of the oscillations, though varying with $p$, is roughly linear in $n$. This is the central assumption that goes into the design of the 'early-late' condition. In ChebPE, we are 'late' whenever the following holds:\n",
    "$$ \\varepsilon_\\text{max}^{T^2} \\cdot \\frac{p_\\text{max} - p_\\text{min}}{|T^2_n(\\sqrt{p_\\text{max}}) - T^2_n(\\sqrt{p_\\text{min}})|} \\leq \\nu \\varepsilon$$\n",
    "where $[p_\\text{min},p_\\text{max}]$ is the current confidence interval on $p$, $\\varepsilon$ is the desired final accuracy, $\\nu$ is a hyperparameter, and $\\varepsilon_\\text{max}^{T^2}$ is the largest possible error in our estimate of $T^2(\\sqrt{p})$ using $N_\\text{shots}$ many shots. Once the late condition holds then $N_{shots}$ might be significantly more shots than necessary to get the desired accuracy, so it makes sense to take the shots one at a time rather than in bunches of $N_\\text{shots}$. The parameter $\\nu$ governs how 'cautiously' we trigger this condition. Optimizing $\\nu$ was the primary source of the speedup in ChebAE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ddf510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import eval_chebyt as cheb\n",
    "from scipy.stats import binom\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import matplotlib.pyplot as plt\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb39d1",
   "metadata": {},
   "source": [
    "# Subroutines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945e51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def invert_T2rootp(T2,n,p_int):\n",
    "    \"\"\" Given T2, find a p such that T2 = T^2_n( sqrt(p) ). There may be multiple solutions so select the closest one to p_int. \"\"\"\n",
    "    \n",
    "    # Just map to the invert function from ChebAE.\n",
    "    # See that function's implementation for detailed comments.\n",
    "    theta_int = np.arccos(np.sqrt(p_int))\n",
    "    c = np.pi/(2*n)\n",
    "    t = np.floor(theta_int/c)\n",
    "    \n",
    "    if t % 2 == 0: theta = np.arccos(2*T2-1)/(2*n)\n",
    "    else: theta = 2*c - np.arccos(2*T2-1)/(2*n)\n",
    "\n",
    "    k = t//2\n",
    "    theta += np.pi*k/n\n",
    "    return np.cos(theta)**2\n",
    "\n",
    "\n",
    "def find_next_k(p_min, p_max, min_k=0):\n",
    "    \"\"\"Find a k >= min_k such that when n = 2k+1 the function T^2_n(sqrt(p)) has no extrema on the interval [p_min, p_max].\"\"\"\n",
    "\n",
    "    # Step 1: convert to theta.\n",
    "    theta_lo = np.arccos(np.sqrt(p_max))\n",
    "    theta_hi = np.arccos(np.sqrt(p_min))\n",
    "    \n",
    "    # Step 2: get highest possible degree.\n",
    "    n = int((np.pi/2)/(theta_hi-theta_lo))\n",
    "    if n % 2 == 0: n += 1 # make it odd\n",
    "\n",
    "    # Step 3: search for the highest degree without any extrema.\n",
    "    while n > 2*min_k+1:\n",
    "        if int(2*n*theta_lo/np.pi) == int(2*n*theta_hi/np.pi):\n",
    "            return (n-1)//2 # Done!\n",
    "        n -= 2           \n",
    "    return None # Couldn't find a degree > min_deg.\n",
    "\n",
    "\n",
    "def max_error_cp(delta, Nshots):\n",
    "    \"\"\" Say we tossed a coin with unknown bias Nshots many times, and we want a confidence interval with confidence >= 1-delta. What is the widest that this interval could be? Relies on Clopper-Pearson confidence interval method.\"\"\"\n",
    "\n",
    "    # Loop over all possible numbers of heads.\n",
    "    max_error = 0\n",
    "    for counts in range(0,Nshots+1):\n",
    "        lower,upper = proportion_confint(counts, Nshots,\n",
    "                                         method=\"beta\",\n",
    "                                         alpha=delta)\n",
    "        if (upper-lower)/2 > max_error:\n",
    "            max_error = (upper-lower)/2\n",
    "    \n",
    "    return max_error   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775186e8",
   "metadata": {},
   "source": [
    "# Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc261b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebpe(p_target, eps, alpha,\n",
    "           nu=8, r=2, Nshots=100):\n",
    "\n",
    "    # Step 1: determine the total number of confidence intervals\n",
    "    # and distribute failure probability budget evenly among them\n",
    "    T = int(np.ceil(np.log(1/(2*eps))/np.log(r)))\n",
    "    alpha_T = alpha/T \n",
    "    \n",
    "    # Step 2: precompute cutoff parameters.\n",
    "    err_max = max_error_cp(alpha_T, Nshots)\n",
    "        \n",
    "    # Step 3: Initialize\n",
    "    p_min, p_max = 0, 1 # confidence interval\n",
    "    num_flips, num_heads = 0, 0 # coin toss tally    \n",
    "    k = 0 \n",
    "    queries = 0 \n",
    "    \n",
    "    # Step 4:\n",
    "    while p_max - p_min > eps*2:\n",
    "\n",
    "        # Step 4(a)\n",
    "        # Try to find a better polynomial with k > r*k.\n",
    "        new_k = find_next_k(p_min, p_max, min_k=r*k)\n",
    "\n",
    "        # Found a better polynomial? If so, reset the counts.\n",
    "        if new_k is not None:\n",
    "            k = new_k\n",
    "            num_flips, num_heads = 0, 0\n",
    "        \n",
    "        # Step 4(b): determine 'late' or 'early' to avoid taking too many samples\n",
    "        # by setting N_shots_i - the number of shots in this iteration\n",
    "        gap = cheb(2*k+1, np.sqrt(p_max))**2 - cheb(2*k+1, np.sqrt(p_min))**2\n",
    "        if err_max * (p_max - p_min)/gap < nu*eps:\n",
    "            Nshots_i = 1      # late: sample one-at-a-time\n",
    "        else:\n",
    "            Nshots_i = Nshots # early: take lots of samples\n",
    "\n",
    "        # Step 4(c): Simulate the quantum computer to toss coins\n",
    "        T2 = cheb(2*k+1, np.sqrt(p_target))**2\n",
    "        for i in range(Nshots_i):\n",
    "            if np.random.random() < T2: num_heads += 1\n",
    "            num_flips += 1\n",
    "            # Our definition of degree is 2*k+1 instead of k\n",
    "            # queries += k\n",
    "            queries += 2*k+1\n",
    "\n",
    "        # Step 4(d): determine confidence interval for prob\n",
    "        T2_min, T2_max = proportion_confint(num_heads, num_flips,\n",
    "                                            method=\"beta\",\n",
    "                                            alpha=alpha_T)\n",
    "        \n",
    "        # Step 4(e): back-propagate [p_min,p_max] to confidence\n",
    "        # interval for [p_min_star, p_max_star] for p_true\n",
    "        p_int = np.mean([p_min,p_max])\n",
    "        p_min_star = invert_T2rootp(T2_min,2*k+1,p_int)\n",
    "        p_max_star = invert_T2rootp(T2_max,2*k+1,p_int)\n",
    "        p_min_star, p_max_star = sorted([p_min_star, p_max_star])\n",
    "\n",
    "        # prevent floating point glitches\n",
    "        p_min_star -= 1e-15\n",
    "        p_max_star += 1e-15\n",
    "\n",
    "        # Step 5(d): update the interval\n",
    "        p_min, p_max = max(p_min, p_min_star), min(p_max, p_max_star)\n",
    "      \n",
    "    return {'algorithm':\"ChebPE\",\n",
    "            'config': {'nu':nu, 'r':r, 'Nshots':Nshots},\n",
    "            'epsilon': eps, \n",
    "            'p_target': p_target,\n",
    "            'alpha': alpha,\n",
    "            'p_estimate': np.mean([p_min,p_max]),\n",
    "            'exact_error': abs(p_target-np.mean([p_min,p_max])),\n",
    "            'ci_width': (p_max - p_min)/2,\n",
    "            'num_oracle_calls': queries}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082d57c",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "450b830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'grid'])\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['figure.figsize'] = (8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a03ae1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [01:22<00:00, 48.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost=112.7735,\tErr*Cost=4.080788868334157,\tErr5%*Cost=0.20600031140643146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [01:40<00:00, 39.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost=176.159,\tErr*Cost=4.487091691737103,\tErr5%*Cost=0.24385554183142394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [02:05<00:00, 31.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost=248.21775,\tErr*Cost=5.014411864019223,\tErr5%*Cost=0.28503833247410065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [02:32<00:00, 26.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost=323.5555,\tErr*Cost=5.5826114585375155,\tErr5%*Cost=0.32174605599461953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [02:52<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost=399.27075,\tErr*Cost=6.330056747407831,\tErr5%*Cost=0.30999890851235323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [03:24<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost=480.5705,\tErr*Cost=7.249639763279713,\tErr5%*Cost=0.34554259831405615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [03:51<00:00, 17.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost=559.6425,\tErr*Cost=7.934615658737897,\tErr5%*Cost=0.4010312427997729\n",
      "OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ress = []\n",
    "for eps in 1/(1<<np.arange(3, 16, 2)):\n",
    "    src = np.random.random(4000)\n",
    "    res = [chebpe(p,0.05,eps) for p in tqdm(src)]\n",
    "    cost = np.sum([r['num_oracle_calls'] for r in res]) / len(res)\n",
    "    err = (sum([r['exact_error']**2 for r in res]) / len(res))**0.5\n",
    "    # calculate the 1% confidence interval for the error\n",
    "    err5p = sorted([r['exact_error'] for r in res])[int(0.05*len(res))]\n",
    "    print(f'Cost={cost},\\tErr*Cost={err*cost},\\tErr5%*Cost={err5p*cost}')\n",
    "    ress.append([cost, err, err5p])\n",
    "np.savetxt('chebpe.txt', ress, fmt='%.6f', delimiter=',')\n",
    "print('OK.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
